{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%matplotlib inline",
   "id": "bf1486428d62b41c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "cell_type": "code",
   "source": [
    "scanbotsdk_license_key: str = None\n",
    "training_dir: str = None\n",
    "explain_image_path: str = None\n",
    "config_debug_path: str = None\n",
    "num_jobs: int = 4"
   ],
   "id": "f1de5d7932a9bfd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Document Quality Analyzer - Debug Analysis",
   "id": "e51982baf08f81e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(f\"For {Path(explain_image_path).relative_to(training_dir)}:\")"
   ],
   "id": "b5a85feb04376c5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The following image visualizes what text the DoQA detects in your image.<br>\n",
    "Based on this information, DoQA will compare the characteristics of your image to the characteristics of images seen during training.\n",
    "If large parts of the document's text (>25%) are not detected at all or are incorrectly annotated, please contact Scanbot SDK support. Please provide the image and this analysis report."
   ],
   "id": "f1a6cdafddaa6a0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import scanbotsdk\n",
    "\n",
    "from character_annotations_plot import plot_annotations\n",
    "\n",
    "training_dir = Path(training_dir)\n",
    "explain_image_path = Path(explain_image_path)\n",
    "\n",
    "scanbotsdk.set_logging(False)\n",
    "scanbotsdk.initialize(scanbotsdk_license_key)\n",
    "document_quality_analyzer = scanbotsdk.DocumentQualityAnalyzerTrainingDataAnnotator()\n",
    "image = scanbotsdk.ImageRef.from_path(explain_image_path)\n",
    "annotations = document_quality_analyzer.run(image=image)\n",
    "\n",
    "plt = plot_annotations(explain_image_path, annotations)\n",
    "plt.show(block=False)"
   ],
   "id": "9f961875786df60e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "from CharacterClusteringTransformer import CharacterClusteringTransformer\n",
    "from PixelClustering import PixelClusteringTransformer\n",
    "import pandas as pd\n",
    "from configurator_utils import  load_samples_from_training_dir, get_character_properties, all_features\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import configurator_utils\n",
    "\n",
    "pixel_clustering: PixelClusteringTransformer = pickle.load(open(config_debug_path, \"rb\"))['pixel_clustering']\n",
    "\n",
    "rgb_color_bin_representatives = pixel_clustering.rgb_color_bin_representatives()\n",
    "\n",
    "gray_pixels = configurator_utils.load_gray_pixels_from_image(explain_image_path)\n",
    "pixel_hist = pixel_clustering.create_hist(gray_pixels)\n",
    "\n",
    "if len(pixel_hist) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    x_positions = range(len(pixel_hist))\n",
    "    bars = ax.bar(x_positions, pixel_hist, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "\n",
    "    for i, (bar, rgb_color) in enumerate(zip(bars, rgb_color_bin_representatives)):\n",
    "        bar_height = bar.get_height()\n",
    "\n",
    "        circle_y = bar_height + max(pixel_hist) * 0.05\n",
    "        circle = plt.Rectangle((i-0.4, circle_y), height=max(pixel_hist) * 0.05, width=.8,\n",
    "                           facecolor=rgb_color, edgecolor='black', linewidth=1, zorder=3)\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "    ax.set_xlabel('Pixel Color')\n",
    "    ax.set_ylabel('Normalized Frequency')\n",
    "    ax.set_title('Pixel Brightness Histogram')\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_ylim(0, max(pixel_hist) * 1.2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=False)"
   ],
   "id": "39d38c4397368b82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Similar images in training data\n",
    "\n",
    "The following images from the training data are most similar to your image.<br>\n",
    "The similarity is in the range 0% (not similar at all) to 100% (identical).<br>\n",
    "Using this information, you can fine-tune your training data: E.g. if you want that your image is classified as \"acceptable\", but it is currently reported as \"unacceptable\" by DoQA, try adding more similar images to the \"good\" training data or removing very similar images from the \"bad\" training data."
   ],
   "id": "cf2e7a9cc798aa65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample = {\n",
    "    \"image_path\": explain_image_path,\n",
    "    \"character_level_annotations\": pd.DataFrame(\n",
    "        get_character_properties(annotations.character_level_annotations, all_features)\n",
    "    ),\n",
    "    f\"pixel_histogram_{pixel_clustering.n_pixel_clusters}\": pixel_hist,\n",
    "}\n",
    "\n",
    "samples = load_samples_from_training_dir(\n",
    "    training_dir=training_dir,\n",
    "    smoke_test=False,\n",
    "    document_quality_analyzer=document_quality_analyzer,\n",
    "    num_jobs=num_jobs,\n",
    "    cache_enabled=True,\n",
    "    show_progress=False,\n",
    ")\n",
    "X = pd.DataFrame(samples)\n",
    "\n",
    "clustering: CharacterClusteringTransformer = pickle.load(open(config_debug_path, \"rb\"))['clustering']\n",
    "\n",
    "good_bad_cluster_hists = clustering.transform(X)\n",
    "sample_cluster_hist = clustering.transform(pd.DataFrame([sample]))[0]\n",
    "\n",
    "max_distance = np.sqrt(len(sample_cluster_hist))\n",
    "X['distance'] = [\n",
    "    np.linalg.norm(sample_cluster_hist - np.asarray(feature_clusters)) / max_distance\n",
    "    for feature_clusters in good_bad_cluster_hists]\n",
    "\n",
    "fig, axs = plt.subplots(5, 5, figsize=(13, 9), height_ratios=[0.03, 1, 0.1, 0.03, 1], tight_layout=True)\n",
    "for ax in axs.flatten():\n",
    "    ax.axis('off')\n",
    "\n",
    "for index, (_, row) in enumerate(X.nsmallest(10, 'distance').iterrows()):\n",
    "    rel_path = Path(row['image_path']).relative_to(training_dir)\n",
    "    similarity = (1 - row['distance']) * 100\n",
    "    title = f\"{rel_path}\\nSimilarity: {similarity:.2f}%\"\n",
    "    x = index % 5\n",
    "    y = (index // 5) * 3\n",
    "    ax_title = axs.flatten()[x + 5*y]\n",
    "    ax_title.set_title(title, fontsize=8)\n",
    "    ax_title.barh([0], [similarity], height=0.5, color='green' if row['label'] == 1 else 'red')\n",
    "    ax_title.barh([0], [100], height=0.5, color='none', edgecolor='black', linewidth=1)\n",
    "    ax_title.set_xlim(0, 100)\n",
    "    ax_title.set_ylim(-0.5, 0.5)\n",
    "    ax_title.set_anchor('S')\n",
    "    ax_img = axs.flatten()[x + 5*(y+1)]\n",
    "    ax_img.imshow(plt.imread(row['image_path']))\n",
    "    ax_img.set_anchor('S')\n",
    "plt.tight_layout()\n",
    "plt.show(block=False)"
   ],
   "id": "26596f8ee282f802",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
